{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T13:22:09.931722Z",
     "start_time": "2025-03-26T13:22:09.690017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,datasets,models,Sequential,optimizers,metrics\n",
    "import datetime\n",
    "(x_train,y_train),(x_test,y_test) = datasets.fashion_mnist.load_data()"
   ],
   "id": "633b586522dffc71",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T13:22:10.027404Z",
     "start_time": "2025-03-26T13:22:09.934712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process(x,y):\n",
    "    x = tf.cast(x,dtype=tf.float32) / 255.\n",
    "    y = tf.cast(y,dtype=tf.int32)\n",
    "    return x,y\n",
    "batch_sz = 128\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
    "train_db = train_db.map(process).shuffle(10000).batch(batch_sz)\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test,y_test))\n",
    "test_db = test_db.map(process).batch(batch_sz)\n"
   ],
   "id": "fd5061cfde80a28d",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T13:22:10.356976Z",
     "start_time": "2025-03-26T13:22:10.038368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_db_iter = iter(train_db)\n",
    "sample_iter = next(train_db_iter)\n",
    "sample_iter[0].shape, sample_iter[1].shape"
   ],
   "id": "5817eb0dca4c3b7b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([128, 28, 28]), TensorShape([128]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T13:22:10.386876Z",
     "start_time": "2025-03-26T13:22:10.366943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        layers.Dense(258, activation='relu'),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(10),\n",
    "    ]\n",
    ")\n",
    "model.build(input_shape=(None, 784))\n",
    "model.summary()"
   ],
   "id": "660e80fcb5ab9a4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 258)               202530    \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 128)               33152     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 246,348\n",
      "Trainable params: 246,348\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T13:22:18.735894Z",
     "start_time": "2025-03-26T13:22:10.397349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 自动优化\n",
    "optimizer = optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "acc_metrics = metrics.Accuracy()\n",
    "loss_metrics = metrics.Mean()\n",
    "\n",
    "log_dir = \"C:/Users/Administrator/Desktop/projects/tensorflow/logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "writer = tf.summary.create_file_writer(log_dir)\n",
    "def forward():\n",
    "    \"\"\"\n",
    "    前向传播\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for step,(x,y) in enumerate(train_db):\n",
    "        x = tf.reshape(x,[-1,784])\n",
    "        with tf.GradientTape() as tape:\n",
    "            # 网络的输出\n",
    "            logits = model(x)\n",
    "            y_onehot = tf.one_hot(y,depth=10)\n",
    "\n",
    "            # 我认为这里也是比较关键，选用什么损失函数来进行反向传播\n",
    "            loss = tf.reduce_mean(tf.keras.losses.MSE(y_onehot,logits))\n",
    "            loss2 = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_onehot,logits,from_logits=True))\n",
    "            loss_metrics.update_state(loss)\n",
    "        #     计算梯度\n",
    "        gradients = tape.gradient(loss2,model.trainable_variables)\n",
    "        #  更新参数\n",
    "        optimizer.apply_gradients(zip(gradients,model.trainable_variables))\n",
    "\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(step,float(loss),float(loss2))\n",
    "            loss_metrics.reset_states()\n",
    "            with writer.as_default():\n",
    "                tf.summary.scalar('train_loss', loss, step=step + epoch * len(train_db))\n",
    "for epoch in range(3):\n",
    "    forward()\n",
    "    corrects,total = 0,0\n",
    "    acc_metrics.reset_states()\n",
    "    for step,(x,y) in enumerate(test_db):\n",
    "        x = tf.reshape(x, (-1,784))\n",
    "        logits = model(x)\n",
    "\n",
    "        prob = tf.nn.softmax(logits,axis=-1)\n",
    "        pred = tf.cast(tf.argmax(prob,axis=-1),dtype=tf.int32)\n",
    "        correct = tf.reduce_sum(tf.cast(tf.equal(pred,y),dtype=tf.int32))\n",
    "        corrects += int(correct)\n",
    "        total += x.shape[0]\n",
    "        acc_metrics.update_state(y,pred)\n",
    "    print(\"Accuracy:\",corrects / total * 100,\"%\",acc_metrics.result().numpy())\n",
    "    with writer.as_default():\n",
    "        tf.summary.scalar('test_accuracy', corrects / total * 100, step=epoch)"
   ],
   "id": "c752269fff9e9dd7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.152599036693573 2.3029565811157227\n",
      "100 17.141860961914062 0.5382728576660156\n",
      "200 22.620223999023438 0.33125609159469604\n",
      "300 20.928707122802734 0.39459073543548584\n",
      "400 19.317501068115234 0.48414361476898193\n",
      "Accuracy: 84.39999999999999 % 0.844\n",
      "0 19.764753341674805 0.38713309168815613\n",
      "100 21.10894012451172 0.3928174674510956\n",
      "200 20.91429901123047 0.2857171297073364\n",
      "300 23.24082374572754 0.5189142823219299\n",
      "400 20.17760467529297 0.3921857476234436\n",
      "Accuracy: 85.26 % 0.8526\n",
      "0 21.058652877807617 0.3926309645175934\n",
      "100 22.836620330810547 0.3252035975456238\n",
      "200 23.857646942138672 0.3607388436794281\n",
      "300 25.43111801147461 0.29877251386642456\n",
      "400 31.291725158691406 0.28947895765304565\n",
      "Accuracy: 85.81 % 0.8581\n"
     ]
    }
   ],
   "execution_count": 38
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
